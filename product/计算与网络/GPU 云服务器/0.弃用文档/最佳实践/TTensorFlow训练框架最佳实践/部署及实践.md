本文介绍如何在 GPU 云服务器实例上部署及使用 TensorFlow。推荐使用 [计算型 GT4](https://cloud.tencent.com/document/product/560/19700#GT4) 实例，可参考 [购买 NVIDIA GPU 实例](https://cloud.tencent.com/document/product/560/30211) 创建实例。




## 安装 TTF
1. 参考 [使用标准登录方式登录 Linux 实例（推荐）](https://cloud.tencent.com/document/product/213/5436)，登录实例。
2. 执行以下命令，通过 docker 镜像的方式安装 TTF。
<dx-codeblock>
:::  shell
docker pull ccr.ccs.tencentyun.com/qcloud/yunfan-ttf1.15-gpu:cu112-cudnn81-py3-0.1.1
:::
</dx-codeblock>
3. 执行以下命令，启动 docker。
<dx-codeblock>
:::  shell
docker run -it --rm --gpus all --shm-size=32g --ulimit memlock=-1 --ulimit stack=67108864 --name ttf1.15-gpu ccr.ccs.tencentyun.com/qcloud/yunfan-ttf1.15-gpu:cu112-cudnn81-py3-0.1.1
:::
</dx-codeblock>
可执行以下命令，查看 TTF 版本。
<dx-codeblock>
:::  shell
pip show ttensorflow
:::
</dx-codeblock>

## 模型适配

### 动态 Embedding
TF 原生的静态 Embedding 及 TTF 提供的动态 Embedding代码如下：
<dx-tabs>
::: TF\s原生的静态\sEmbedding
<dx-codeblock>
:::  python
deep_dynamic_variables = tf.get_variable(
    name="deep_dynamic_embeddings",
    initializer=tf.compat.v1.random_normal_initializer(0, 0.005),
    shape=[100000000, self.embedding_size])
    
deep_sparse_weights = tf.nn.embedding_lookup(
    params=deep_dynamic_variables,
    ids=ft_sparse_val,
    name="deep_sparse_weights")
    
deep_embedding = tf.gather(deep_sparse_weights, ft_sparse_idx)
deep_embedding = tf.reshape(
    deep_embedding,
    shape=[self.batch_size, self.feature_num * self.embedding_size])
:::
</dx-codeblock>
::: 
::: TTF\s提供的动态\sEmbedding
<dx-codeblock>
:::  python
deep_dynamic_variables = tf.dynamic_embedding.get_variable(       
    name="deep_dynamic_embeddings",                               
    initializer=tf.compat.v1.random_normal_initializer(0, 0.005), 
    dim=self.embedding_size,                                      
    devices=["/{}:0".format(FLAGS.device)],                       
    init_size=100000000)             
		
deep_sparse_weights = tf.dynamic_embedding.embedding_lookup(      
    params=deep_dynamic_variables,                                
    ids=ft_sparse_val,                                            
    name="deep_sparse_weights")   
       
deep_embedding = tf.gather(deep_sparse_weights, ft_sparse_idx)    
deep_embedding = tf.reshape(
    deep_embedding,
    shape=[self.batch_size, self.feature_num * self.embedding_size])
:::
</dx-codeblock>
:::
</dx-tabs>

TTF 仅对以下两部分进行替换，使用非常便利：
-  embedding 使用 [`tf.dynamic_embedding.get_variable()`](https://github.com/tensorflow/recommenders-addons/blob/master/docs/api_docs/tfra/dynamic_embedding/get_variable.md)。
- lookup 使用 [`tf.dynamic_embedding.embedding_lookup()`](https://github.com/tensorflow/recommenders-addons/blob/master/docs/api_docs/tfra/dynamic_embedding/embedding_lookup.md)。
详细的 API 使用说明文档请参见 [Module: tfra.dynamic_embedding](https://github.com/tensorflow/recommenders-addons/blob/master/docs/api_docs/tfra/dynamic_embedding.md)。

### 混合精度
混合精度既可以通过代码对优化器进行重写，也可通过修改环境变量实现。如下所示：
- 代码修改的方式
<dx-codeblock>
:::  shell
opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)
:::
</dx-codeblock>
- 环境变量方式
<dx-codeblock>
:::  shell
export TF_ENABLE_AUTO_MIXED_PRECISION=1
:::
</dx-codeblock>

### XLA
XLA 既可以通过代码进行配置，也可通过修改环境变量实现。如下所示：
- 代码修改的方式
<dx-codeblock>
:::  shell
config = tf.ConfigProto()
config.graph_options.optimizer_options.global_jit_level = tf.OptimizerOptions.ON_1
sess = tf.Session(config=config)
:::
</dx-codeblock>
- 环境变量的方式
<dx-codeblock>
:::  shell
TF_XLA_FLAGS=--tf_xla_auto_jit=1
:::
</dx-codeblock>


## Demo
在运行 Demo 前：
1. 执行以下命令，在实例中创建一个固定的位置存放数据集，且总共不超过200M。
<dx-codeblock>
:::  shell
cd /ttensorflow/dynamic-embedding-demo
:::
</dx-codeblock>
2. 执行以下命令，下载数据集。
<dx-codeblock>
:::  shell
bash download_dataset.sh 
:::
</dx-codeblock>
您可根据以下 Demo，快速了解并使用 TTF。

### benchmark
该 Demo 用于对比测试动态 embedding 和原生静态 embedding 的性能。可依次执行以下命令，运行 Demo：
<dx-codeblock>
:::  shell
cd benchmark
// 按照默认配置运行
python train.py

// 每次修改batch size，需要将本地数据集缓存文件删掉
rm -f .index .data-00000-of-00001
python train.py --batch_size=16384

// 分别使用静态embedding和动态embedding进行DeepFM模型训练
python train.py --batch_size=16384 --is_dynamic=False
python train.py --batch_size=16384 --is_dynamic=True

// 调整Deep部分的fc层数
python train.py --batch_size=16384 --dnn_layer_num=12
:::
</dx-codeblock>

### ps
该 Demo 展示如何在 ps 模式下使用动态 embedding。可执行以下命令，运行 Demo：
<dx-codeblock>
:::  shell
cd ps && bash start.sh
:::
</dx-codeblock>

### Estimator
该 Demo 展示如何在 Estimator 模式下使用动态 embedding。可执行以下命令，运行 Demo：
<dx-codeblock>
:::  shell
cd estimator && bash start.sh
:::
</dx-codeblock>
