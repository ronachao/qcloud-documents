## 业内常见分表规则
关系型数据库是一个二维模型，数据的切分通常就需要找到一个分表字段以确定拆分维度，再通过定义规则来实现数据库的拆分。业内的几种常见的分表规则如下：
- 	基于某字段求模（Hash）
 	将求模后字段的特定范围分散到不同库中。
- 	基于日期或字段范围（Range）
如按年拆分，2020 年一个分表，2021 年一个分表 。
如按用户 ID 划分，0~1000 一个分表，1001~2000 一个分表。
- 基于枚举值列表（List）
-  按满足某些固定条件的数据分散到不同库中。
>!LIST和RANGE类似，区别在于LIST是枚举值列表的集合，RANGE是连续的区间值的集合。

## 各分表规则适用场景
### RANGE规则适用场景
- 业务表数据量非常大，表存在日期或时间类型的字段
- 该字段通常不会被更新，很多查询语句都包含该字段
- 选该字段为分区键可以使得各个分区上的数据分配的比较均衡
- 可能需要定期按时间清理历史数据
业务场景举例：用户登录日志表
- 用户每次登录都会记录登录日志
- 用户登录日志保存一年，1年后按照时间删除或者归档
- 以login_time（登录时间）为分表键

###  LIST规则适用场景
- 	业务表数据量非常大，存在可以按分区键取值的列表进行分区
- 	同范围分区一样，各分区的列表值不能重复
- 	该字段通常不会被更新，很多查询语句都包含该字段
- 	每一行数据必须能找到对应的分区列表，否则数据插入失败
业务场景举例：城市常驻人口信息表
- 	以city_district（城市行政区：0 东区 1西区 2南区 3北区）为分表键
- 	将不同行政区的人口信息存入对应分区进行管理

###  HASH规则适用场景
无论是 Time、Range ，大部分业务场景都容易导致比较严重的数据倾斜，即分片之间负载和数据容量严重不
均衡。例如，在大部分数据库系统中，数据有明显的冷热特征——例如当前的订单被访问的概率比半年前的订单要高的多。而采用 Time 分表或 range 分表，就意味着很容易出现大部分热数据将会被路由在少数几分片中，而剩下的分片设备性能却被白白浪费掉了。而采用某个字段求模（Hash）的方案进行分表就不会出现这种问题，因为 Hash 算法的原理能够基本保证数据相对均匀的分散在不同的物理设备中。
业务场景举例：商品订单表
- 以user_id（用户ID）进行HASH分区
- 用户ID是该表的主键

### 数据rebalance
#### 概念介绍：
假设现在有一个表A，create table A(a int key, b int) local_table_options distributed by range(a) (s1 values less than(100)); 其数据分布在set1上: distributed by range(a) (s1 values less than(100)); 现在想在尽量不影响业务的情况下，把该表的数据进行重分布，使得重分布后的A表其数据分布为：distributed by range(a) (s1 values less than(50) , s2 values less than(100)); 即将原先分布在set1上的数据重分布到set1和set2上。rebalance工具要求尽量不影响业务，故讨论决定大表(记录大于等于30w)使用多源同步，小表根据是否有自增列决定是采用musqldump+insert into或者insert...select的方式导入。
#### 工具配置文件介绍：
工具位于`proxy/bin/rebalance/`目录下，共有四个文件，其中autoincre_table.sh和noautoincre_table.sh脚本为依赖脚本，被rebalance.sh脚本调用，rebalance.config为配置文件。

#### 配置文件rebalance.config介绍：
database="rebalance"  #数据库名
table="t1" #需要重分布的表名
rebalance="TDSQL_DISTRIBUTED BY RANGE(b) (s1 values less than 	('200'));" #重分布语句，用于建新表
divide="300000"  #暂时不用
ip="9.30.17.168" #数据库ip 
use="test"  #数据库用户
passwd="test123"    #数据库用户密码   
port="15064" #连接数据库的proxy端口

#### 使用介绍：
首先将配置文件与3个脚本文件放在同一个目录下，按要求填写好rebalance.config并保存。然后运行rebalance.sh脚本即可。重分布完成后可以发现在相应数据库中指定的表A被新表A（按照指定重分布语句进行构造，数据与旧表一致）接替工作，旧表的表结构和数据会保存为A_bak表的形式存在。
重分布方案步骤如下：
1. 通过proxy端口进行mysqldump获得A表的建表语句，通过字符匹配修改，结合输入参数，形成分表B的建表语句，通过proxy新建该分表B表。
1. 通过proxy对A表的记录数进行判断：select count(*) from A;当记录数小于30w行时，进入步骤3；当记录数大于等于30w时，进入步骤4。
1. 小数据量的表处理方法：锁表，mysqldump导出数据，字符串替换将sql更换为导入B表。执行sql文件insert into到分表B（如果没有自增列，可以使用proxy提供的insert…select来实现），通过rename的方式将A更名为A_bak1,B更名为A，解锁。
1. 大数据量的表处理方法：调用多源同步的接口创建同步任务（srcid为相应setid，dstid为groupid，采用精确匹配找到相应的源表A和目标表B），全量同步A和分表B，监控延迟，当延迟小于等于4s时认为同步快要结束，此时锁表，再次监控延迟，当延迟小于等于4s时执行rename，将A更名为A_bak1,B更名为A，解锁，停止多源同步任务。
