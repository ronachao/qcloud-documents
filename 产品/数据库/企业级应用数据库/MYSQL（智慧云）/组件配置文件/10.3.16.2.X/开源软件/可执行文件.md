## crontab
| 模块                                                         | 任务详细                                                     | 任务说明                                 |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------------- |
| tdsql_begining                                               | cd /data/oc_agent/scripts; ./agent_monitor.sh                | 监控节点agent运行情况                    |
| cd /data/monitorcmd; ./monitoriotop.sh                       | 监控所有的磁盘和文件系统的磁盘 I/O信息                       |                                          |
| tdsql_zk_cluster                                             | /bin/bash /data/tools/check_zk_alive.sh                      | zookeeper集群存活检测                    |
| tdsql_chitu                                                  | /usr/local/php/bin/php /data/website/tdsqlpcloud/index.php cron cluster statistics | 定期刷新集群状态和信息                   |
| /usr/local/php/bin/php /data/website/tdsqlpcloud/index.php cron oss2db run | 定期从OSS获取实例，mysql，proxy信息同步到监控库，判断是否下架 |                                          |
| /usr/local/php/bin/php /data/website/tdsqlpcloud/index.php cron workflow run | 定期后台执行没有运行的异步任务                               |                                          |
| /usr/local/php/bin/php /data/website/tdsqlpcloud/index.php cron dbcluster statistics_client | 定期统计实例的request_total_select_sum，request_total_modify_sum等信息到监控库 |                                          |
| /usr/local/php/bin/php  /data/website/tdsqlpcloud/index.php cron dcnjob run | 定期从OSS获取dcn信息同步到赤兔系统库                         |                                          |
| /usr/local/php/bin/php /data/website/tdsqlpcloud/index.php cron syncjob run | 定期从OSS获取多源同步信息同步到赤兔系统库                    |                                          |
| /usr/local/php/bin/php /data/website/chitu/tdsqlpcloud/index.php cron dbuser_privileges run | 对尚未执行完的授权单任务进行离线处理                         |                                          |
| /usr/local/php/bin/php /data/website/tdsqlpcloud/index.php cron dbuser_apply run | 对尚未执行完的申请单任务进行离线处理                         |                                          |
| /usr/local/php/bin/php /data/website/chitu/tdsqlpcloud/index.php cron cluster sync_to_local | #集群信息同步到本地文件                                      |                                          |
| /bin/bash /data/tools/check_nginx_alive.sh                   | nginx进程存活监控                                            |                                          |
| /bin/bash /data/tools/check_php_alive.sh                     | php-fpm进程存活监控                                          |                                          |
| tdsql_oss                                                    | /bin/bash /data/tools/check_oss_alive.sh                     | oss进程存活监控                          |
| tdsql_collector_analyer                                      | /bin/bash /data/tools/check_coll_any_alive.sh                | collector/analyze进程存活监控            |
| tdsql_scheduler                                              | /bin/bash /data/tools/check_scheduler_alive.sh               | scheduler进程存活监控                    |
| cd /data/application/scheduler/bin;./backupZkInfo            | zookeeper备份                                                |                                          |
| tdsql_clouddba                                               | /bin/bash /data/tools/check_clo_alive.sh                     | tdsql-diagnosis进程(clouddba)存活监控    |
| tdsql_onlineddl                                              | /bin/bash /data/tools/check_onlineddl_alive.sh               | ddlperformermng进程存活监控              |
| tdsql_consumer                                               | /usr/bin/python /data/application/consumer/bin/multisrcsync_log_bak_clean.py | 定期备份和清理由binlogconsumer生成的日志 |

## mysqlagent
<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/tdsql_run/4001/mysqlagent/bin/</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>agent_config</td><td>agent配置工具，例如修改agent的端口等</td><td>./agent_config --mode modify|remove| --option=&quot;ocagent_port&quot; --value=&quot;8966&quot;</td></tr><tr><td>alldump.sh</td><td>支持不同存储引擎数据库实例的压缩多线程流备份</td><td>./alldump.sh cnffile user pass unixsock tmpdir loginpass dstip dsttmpdir dstbindir srchost srcport limit oc_port  for example: ./alldump.sh \ /data/home/tdengine/mariadb-10.0.10-prefix/etc/my_4001.cnf agent agent123456 \ /data/4001/prod/mysql.sock  \ &#39;/data/log/4001/dblogs/tmp&#39; \ tdengine \ 10.187.143.217 \ &#39;/data/4002/dbdata_raw/xtrabackuptmp&#39; \ &#39;/data/home/tdengine/mysqlagent/bin&#39; \ 10.187.143.217 4001 0</td></tr><tr><td>autocheckhigh2</td><td>指定pstack开始执行分析的线程阀值</td><td>./autocheckhigh2 --conf my3318.cnf --active 10 --wait 5 --pstack_wait_thread 3  --pstack_run_max 30</td></tr><tr><td>autorepair</td><td>自动修复</td><td>　</td></tr><tr><td>binlogproducter</td><td>解析所在节点的 binlog并push到消息队列</td><td>./binlogproducter  ../conf/mysqlagent_4001.xml</td></tr><tr><td>binlogproducter_percona</td><td>binlogproducter_percona版本</td><td>./binlogproducter_percona ../conf/mysqlagent_4001.xml</td></tr><tr><td>cgroup_check.sh</td><td>检查指定port对应的cgroup pid</td><td>./cgroup_check.sh port</td></tr><tr><td>checkdisk</td><td>磁盘检查</td><td>./checkdisk -p /data5</td></tr><tr><td>cold_mydumper_to_cos.sh</td><td>利用mysqldumper将数据冷备到腾讯云对象存储上(Cloud Object Storage)</td><td>./cold_mydumper_to_cos.sh user pass unixsock hdfsdir filename</td></tr><tr><td>cold_mydumper_to_hdfs.sh</td><td>利用mysqldumper将数据冷备到HDFS上</td><td>./cold_mydumper_to_hdfs.sh user pass unixsock hdfsdir filename resultfile mydumperParam[optional]</td></tr><tr><td>cold_mydumper_to_localfile.sh</td><td>利用mysqldumper将数据冷备到本地路径</td><td>./cold_mydumper_to_localfile.sh user pass unixsock localdir filename resultfile mydumperParam[optional]</td></tr><tr><td>cold_xtrabackup_increment_to_cos.sh</td><td>利用_xtrabackup将数据增备到腾讯云对象存储上(Cloud Object Storage)</td><td>./cold_xtrabackup_increment_to_cos.sh cnffile user pass unixsock tmpdir limit hdfspath</td></tr><tr><td>cold_xtrabackup_increment_to_hdfs.sh</td><td>利用_xtrabackup将数据增备到HDFS上</td><td>./cold_xtrabackup_increment_to_hdfs.sh  cnffile user pass unixsock tmpdir limit hdfspath</td></tr><tr><td>cold_xtrabackup_increment_to_localfile.sh</td><td>利用_xtrabackup将数据增备到本地路径</td><td>./cold_xtrabackup_increment_to_localfile.sh cnffile user pass unixsock tmpdir limit path</td></tr><tr><td>cold_xtrabackup_to_cos.sh</td><td>利用_xtrabackup将数据全备到腾讯云对象存储上(Cloud Object Storage)</td><td>./cold_xtrabackup_to_cos.sh cnffile user pass unixsock tmpdir limit hdfspath</td></tr><tr><td>cold_xtrabackup_to_hdfs.sh</td><td>利用_xtrabackup将数据全备到HDFS上</td><td>./cold_xtrabackup_to_hdfs.sh cnffile user pass unixsock tmpdir limit hdfspath</td></tr><tr><td>cold_xtrabackup_to_localfile.sh</td><td>利用_xtrabackup将数据全备到本地路径</td><td>cold_xtrabackup_to_localfile.sh cnffile user pass unixsock tmpdir limit hdfspath</td></tr><tr><td>cos_tool.py</td><td>由cold_mydumper_to_cos.sh、cold_xtrabackup_increment_to_cos.sh、cold_xtrabackup_to_cos.sh脚本调用</td><td>无需单独使用</td></tr><tr><td>dcntool</td><td>DCN同步工具</td><td>./dcntool builddcnslave masterzkiplist masterzk_homepath master_set  slavezkiplist slavezk_homepath slave_set</td></tr><tr><td>decompression</td><td>解压缩工具</td><td>./decompression file.compress</td></tr><tr><td>drop_backup</td><td>备份删除工具</td><td>./drop_backup --zkdir /tdsqlzk --savedays 10</td></tr><tr><td>encrypt</td><td>加密工具</td><td>./encrypt 要加密的字符串</td></tr><tr><td>encrypt_tool</td><td>加密工具(只支持0和1的加密)</td><td>./encrypt_tool  0 111111</td></tr><tr><td>getlastgtid</td><td>获取最新的GTID</td><td>./getlastgtid --mysqletcfile my.cnf --binlogprefix  mysql-bin</td></tr><tr><td>getlastgtidbytime</td><td>获取最新的GTID对应的时间</td><td>./getlastgtid --mysqletcfile my.cnf --binlogprefix  mysql-bin</td></tr><tr><td>getNetSpeed.sh</td><td>获取指定IP的网速信息</td><td>./getNetSpeed.sh ip_addr</td></tr><tr><td>gtidlistcache_percona</td><td>获取指定binlog cache中的GTID信息</td><td>./gtidlistcache_percona --mysqletcfile my.cnf --binlogprefix mysql-bin</td></tr><tr><td>gtidlist_percona</td><td>获取指定binlog中的GTID信息</td><td>/gtidlist_percona binlog.000016</td></tr><tr><td>gtidprint</td><td>获取连续的gitd信息</td><td>无需单独使用</td></tr><tr><td>gtidprint_percona</td><td>获取连续的gitd信息</td><td>无需单独使用</td></tr><tr><td>gtidtofilepos</td><td>根据gtid获取binlog的位点信息</td><td>/gtidtofilepos_percona --mysqletcfile=&quot;&quot;  --binlogprefix=&quot;binlog&quot; --gtidlist=&quot;&quot;</td></tr><tr><td>gtidtofilepos_percona</td><td>根据gtid获取binlog的位点信息</td><td>/gtidtofilepos_percona --mysqletcfile=&quot;&quot;  --binlogprefix=&quot;binlog&quot; --gtidlist=&quot;&quot;</td></tr><tr><td>initcgrouphierarchy.sh</td><td>cgroup初始化脚本</td><td>　</td></tr><tr><td>install_single_proxy</td><td>安装single proxy，该文件位于/data/home/tdsql/tdsqlinstall/目录下</td><td>　</td></tr><tr><td>install_tdsql_zkparam</td><td>安装zk，该文件位于/data/home/tdsql/tdsqlinstall/目录下</td><td>　</td></tr><tr><td>kms_tool.py</td><td>通过备份文件恢复实例时，用于解密加密的备份数据</td><td>python ./kms_tool.py --role=&quot;qcs::cam::uin/xxxxxxxxx:roleName/kmsTDSQLRole&quot;  --secret_id=&quot;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot; --secret_key=&quot;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot; --region=&quot;ap-hongkong&quot; --ciphertext=&quot;CtFlCxx0+LilyvZ5xxqSIA/KEhVexxIGfBwzXiMShQZxxxWAUsHcfLQ0xxxDH2D49/nOw==-k-fKVP3WxxxMW4jEkQ==-k-zudP3Tz4jxrxxxKkuKU+0V/gVVaxxIaRl/+83qCinaBxxU5e1MpW4q/IJKpxxb9N9/rO 5Es03fxxxn8Sjex6mnl+YKV1SMQog+RJ1xxxNmwx/22hhHb/1B5LGpwB8tbXKD3gL0tZwSxxxUnONh5+6ssb2cxxxBhGj9oXtbL6OC74PuDO1D/AsQ6qBxxxTSA68s8Q=&quot;</td></tr><tr><td>libiconv.so.2</td><td>动态链接库文件，不可执行的二进制程序文件，允许程序共享执行特殊任务所必需的代码和其他资源</td><td>　</td></tr><tr><td>libmysqlclient.so.20</td><td>动态链接库文件，不可执行的二进制程序文件，允许程序共享执行特殊任务所必需的代码和其他资源</td><td>　</td></tr><tr><td>lz4</td><td>解压缩工具</td><td>压缩： lz4 filename  解压缩： lz4 -d filename.lz4</td></tr><tr><td>migrate.sh</td><td>迁移工具</td><td>　</td></tr><tr><td>mydumper</td><td>tdsql for mysql多线程数据dump工具</td><td> ./mydumper -u root -p password -B test -0 /mydumper/</td></tr><tr><td>myloader</td><td>将mysqldump出来的sql以并行的方式进行恢复</td><td>./myloader -u root -p password -B test -d /mydumper</td></tr><tr><td>mysqlbinlog</td><td>获取当前二进制日志列表，mysqlbinlog默认行为等</td><td>./mysqlbinlog [options] log-files</td></tr><tr><td>mysqlbinlog_flashback</td><td>生成反向SQL完成回退</td><td>./mysqlbinlog_flashback --user arg --pass arg --host arg --port arg --start-position arg --maxTimeRange arg</td></tr><tr><td>mysqlbinlog_flashback_percona</td><td>生成反向SQL完成回退_percona版本</td><td>./mysqlbinlog_flashback --user arg --pass arg --host arg --port arg --start-position arg --maxTimeRange arg</td></tr><tr><td>mysql_insert_test</td><td>多线程insert工具</td><td>./mysql_insert_test -h  100.10.1.100 -P 15000 -u clouddba -pclouddba -t 8</td></tr><tr><td>mysql_param_modify</td><td>参数指定set修改工具</td><td>./mysql_param_modify --agent-conf arg --mode modify --name set</td></tr><tr><td>mysqlrecoverfromxtrabackup</td><td>xtrabackup实例恢复工具</td><td>./mysqlrecoverfromxtrabackup --etcfile my.cnf --user dbuser --pass password</td></tr><tr><td>mysqlrecoverset</td><td>set恢复工具</td><td>./mysqlrecoverset --setname arg --zkhome [zookeeper root dir] --etcfile my.cnf --endtimestamp 需要恢复到的时间点</td></tr><tr><td>mysqlreport</td><td>agent上报进程</td><td>./mysqlreport ../conf/mysqlagent_4001.xml</td></tr><tr><td>oc_encrypt</td><td>oc加密工具</td><td>./oc_encrypt 要加密的字符</td></tr><tr><td>oc_tool</td><td>oc配置工具</td><td>oc_tool [-fdkcvn] [-o option] [-P port] [-l ratelimit] [-t timeout] [-p password]  [user@]hostname [command]</td></tr><tr><td>parse-processlist-log.sh</td><td>线程日志分析</td><td>./parse-processlist-log.sh since_time(int) until_time(int) &#39;processlist-log1 processlist-log2 ...&#39;</td></tr><tr><td>procmonitor</td><td>进程监视器</td><td>./procmonitor --conffile arg</td></tr><tr><td>pt-query-digest</td><td>慢查询分析工具</td><td>./pt-query-digest /usr/local/mysql/data/slow.log</td></tr><tr><td>pt-table-checksum</td><td>校验主从数据一致性</td><td>./pt-table-checksum h=MASTER_HOST,u=repl_user,p=&#39;repl_pass&#39;,P=3306 \ --databases=d_test --tables=t_user,t_user_detail,t_user_group --nocheck-replication-filters</td></tr><tr><td>pt-table-sync</td><td>用于修复主从不一致的数据</td><td>对指定的表进行sync： ./pt-table-sync --charset=utf8--ignore-databases=mysql,sys  --databases=test_tdsql --tables=test_nu--no-check-slave dsn=u=root,p=root,h=源端IP,P=3306dsn=u=root,p=root,h=目标端IP,P=3306 --execute --print</td></tr><tr><td>pv</td><td>Pipe Viewer，管道的过程进度对用户透明</td><td>./pv -cN source access.log | gzip | pv -cN gzip &gt; access.log.gz</td></tr><tr><td>reinstall_mysql</td><td>重装mysqlagent</td><td>./reinstall_mysql --agent-conf  ../conf/mysqlagent_4001.xml --mysql-param innodb_page_size=1638  --ignore_check_master 1 --setname newset</td></tr><tr><td>relayhbts_mariadb</td><td>查看从库延迟情况_mariadb版本</td><td>./relayhbts_mariadb --mysqletcfile my.cnf --relaylogprefix relay --delay 2</td></tr><tr><td>relayhbts_percona</td><td>查看从库延迟情况_percona版本</td><td>./relayhbts_percona --mysqletcfile my.cnf --relaylogprefix relay --delay 2</td></tr><tr><td>relaylogrepair</td><td>relaylog修复工具</td><td>./relaylogrepair port option[relaylognum resetslave]</td></tr><tr><td>relaymasterpos_percona</td><td>relaylog位置信息_percona版本</td><td>./relaymasterpos_percona  --mysqletcfile my.cnf --relaylogprefix relay</td></tr><tr><td>repairsysdb_mariadb</td><td>sysdb修复工具_mariadb版</td><td>./repairsysdb_mariadb --relaylog arg --start-position arg --port arg </td></tr><tr><td>repairsysdb_percona</td><td>sysdb修复工具_percona版</td><td>./repairsysdb_percona --relaylog arg --start-position arg --port arg </td></tr><tr><td>replacetemplate</td><td>模板替换</td><td>./replacetemplate templatefile outputfile req</td></tr><tr><td>restartbinlogproduct_cgroup.sh</td><td>重启binlogproduct进程，会调用stopbinlogproduct.sh和startbinlogproduct_cgroup.sh</td><td>./restartbinlogproduct_cgroup.sh ../conf/mysqlagent_4001.xml</td></tr><tr><td>restartbinlogproduct.sh</td><td>重启binlogproduct进程，会调用stopbinlogproduct.sh和startbinlogproduct.sh</td><td>./restartbinlogproduct.sh ../conf/mysqlagent_4001.xml</td></tr><tr><td>restartbinlogtofile.sh</td><td>重启binlogproduct进程，会调用stopbinlogtofile.sh和startbinlogtofile.sh</td><td>./restartbinlogtofile  ../conf/mysqlagent_4001.xml</td></tr><tr><td>restartreport_cgroup.sh</td><td>重启report进程，会调用stopreport.sh和startreport_cgroup.sh脚本</td><td>./restartreport_cgroup.sh ../conf/mysqlagent_4001.xml</td></tr><tr><td>restartreport.sh</td><td>重启report进程，会调用stopreport.sh和startreport.sh脚本</td><td>./restartreport.sh ../conf/mysqlagent_4001.xml</td></tr><tr><td>restarttransfer.sh</td><td>重启transfer进程，会调用stoptransfer.sh和starttransfer.sh脚本</td><td>./restarttransfer.sh ../conf/mysqlagent_4001.xml</td></tr><tr><td>safeshell</td><td>用于Ruby开发的安全shell环境(SafeShell lets you execute shell commands and get the resulting output, but without the security problems of Ruby&#39;s backtick operator.)</td><td>./safeshell &#39;[cmd]&#39;</td></tr><tr><td>srm</td><td>tdsql慢删除工具</td><td>./srm [filename]</td></tr><tr><td>srmnew</td><td>tdsql慢删除工具</td><td>./srmnew [-c countPerSec(default is 4)]  filelist</td></tr><tr><td>sshpass</td><td>用于非交互的ssh 密码验证，使用-p参数指定明文密码，然后直接登录远程服务器</td><td>sshpass -p xxx ssh root@ip</td></tr><tr><td>startbinlogproduct_cgroup.sh</td><td>启动binlogproduct进程，会调用startbinlogproduct.sh脚本</td><td>./startbinlogproduct_cgroup.sh  ../conf/mysqlagent_4001.xml</td></tr><tr><td>startbinlogproduct.sh</td><td>启动binlogproduct进程</td><td>./startbinlogproduct.sh  ../conf/mysqlagent_4001.xml</td></tr><tr><td>startbinlogtofile.sh</td><td>启动binlogtofile进程</td><td>　</td></tr><tr><td>startreport_cgroup.sh</td><td>启动agent上报，会调用到startreport.sh脚本</td><td>./startreport_cgroup.sh ../conf/mysqlagent_4001.xml </td></tr><tr><td>startreport.sh</td><td>启动agent上报</td><td>./startreport.sh ../conf/mysqlagent_4001.xml  </td></tr><tr><td>stopbinlogconsumer.sh</td><td>停止binlogconsumer进程</td><td>./stopbinlogconsumer.sh</td></tr><tr><td>stopbinlogproduct.sh</td><td>停止binlogproduct进程</td><td>./stopbinlogproduct.sh</td></tr><tr><td>stopreport.sh</td><td>停止agent上报</td><td>./stopreport.sh  ../conf/mysqlagent_4001.xml  </td></tr><tr><td>tdsql_addto_cgroup</td><td>用于将instance加入到cgroup</td><td>./tdsql_addto_cgroup  --port mysql_instance_port \ --pid xxx --cgrouptype cpu,blkio</td></tr><tr><td>tdsql_cgroup_build</td><td>用于cgroup对instance配置编排</td><td>./tdsql_cgroup_build --instanceport instanceport --cpu_percent 20 --mode add|modify|init</td></tr><tr><td>tdsql_keyring</td><td>tdsql秘钥配置工具，生成或者获取指定mysql实例的keyring_file</td><td>./tdsql_keyring --keyring-file arg --server-uuid --mode fetch|store</td></tr><tr><td>transfer_account</td><td>用来验证主备切换数据一致性，首先建立账户表，并完成初始化账户余额。然后，多线程转账，对于update成功的程序同步更新内存中的数据，对于udpate超时，程序尝试select二次查询的方式确认更新是否成功，最终比较数据库中的值和内存中的值是否一致。</td><td>./transfer_account -h 127.0.0.1 -P 4001 -u clouddba -p clouddba -t 10 -T 20 --tables 4</td></tr><tr><td>truncatebinlog</td><td>截断binlog</td><td>./truncatebinlog endTime</td></tr><tr><td>truncatebinlog_percona</td><td>截断binlog_percona版本</td><td>./truncatebinlog_percona endTime</td></tr><tr><td>truncatFileFromEnd.sh</td><td>截断文件，从末尾开始</td><td>./truncatFileFromEnd.sh file reserveSize(MB)</td></tr><tr><td>uninstall_single_proxy</td><td>卸载single proxy，该文件位于/data/home/tdsql/tdsqlinstall/目录下</td><td>./uninstall_single_proxy</td></tr><tr><td>uninstall_single_tdsql</td><td>卸载single tdsql，该文件位于/data/home/tdsql/tdsqlinstall/目录下</td><td>./uninstall_single_tdsql</td></tr><tr><td>xatool</td><td>xa分析工具</td><td>./xatool --begin-timestamp arg --end-timestamp arg</td></tr><tr><td>zkinfo_copy</td><td>zk信息复制</td><td>./zkinfo_copy --src-zklist arg -src-zkdir arg --srcname arg --dstname arg</td></tr></tbody>
</table></figure>

## oc_agent
<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/oc_agent/bin/</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>ewp_tdsql_oc</td><td>用于运行oc_agent</td><td>/ewp_tdsql_oc /data/oc_agent/bin --config=../conf/oc_agent.xml</td></tr><tr><td>ewp_tdsql_proc</td><td>用于运行agent proc</td><td>./ewp_tdsql_proc /data/oc_agent/bin</td></tr><tr><td>ewp_tdsql_proc.err</td><td>ewp_tdsql_proc进程错误日志</td><td>tail -100f /data/oc_agent/bin/ewp_tdsql_proc.err</td></tr><tr><td>ewp_tdsql_proc.log</td><td>ewp_tdsql_proc进程常规日志</td><td>tail -100f /data/oc_agent/bin/ewp_tdsql_proc.err</td></tr><tr><td>oc_encrypt</td><td>密码加密</td><td>./oc_encrypt -[s|c] password</td></tr><tr><td>oc_passwd</td><td>用来从密码文件(/etc/passwd)中读取一项用户数据, 该用户的数据以passwd 结构返回.</td><td>./oc_passwd tdsql</td></tr><tr><td>oc_tool</td><td>oc配置工具</td><td>usage: oc_tool [-fdkcvn] [-o option] [-P port] [-l ratelimit] [-t timeout] [-p password]         [user@]hostname [command]</td></tr><tr><td>restart.sh</td><td>重启ewp_tdsql_proc进程</td><td>/data/oc_agent/bin/restart.sh </td></tr><tr><td>safeshell</td><td>用于Ruby开发的安全shell环境(SafeShell lets you execute shell commands and get the resulting output, but without the security problems of Ruby&#39;s backtick operator.)</td><td>非执行文件</td></tr><tr><td>start_agent.sh</td><td>启动ewp_tdsql_proc进程</td><td>/data/oc_agent/bin/start_agent.sh</td></tr><tr><td>stop_agent.sh</td><td>停止ewp_tdsql_proc、ewp_tdsql_oc、AgentCollector进程</td><td>/data/oc_agent/bin/stop_agent.sh</td></tr><tr><td>struncate</td><td>f</td><td>./struncate [filename]</td></tr><tr><td>szrz</td><td>执行oc_agent编译的脚本</td><td>由/data/tools下的文件调用</td></tr></tbody>
</table></figure>

## proxy
<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/tdsql_run/15001/gateway/bin/</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>change_rootdir_all.sh</td><td>修改zookeeper根目录至cgroup,xa,noshard模式</td><td>./change_rootdir_all.sh instance  /newrootdir/dir  1 1 1</td></tr><tr><td>change_rootdir_no_cgroup.sh</td><td>修改zookeeper根目录至非cgroup模式，可以自定义是否启用xa模式</td><td>./change_rootdir_no_cgroup.sh instance /newrootdir/dir  0 1 1</td></tr><tr><td>change_rootdir.sh</td><td>修改zookeeper根目录至cgroup模式，可以自定义是否启用xa模式</td><td>./change_rootdir.sh instance /newrootdir/dir  1 1 0</td></tr><tr><td>change_rootdir_to_noshard.sh</td><td>修改zookeeper根目录至noshard模式</td><td>./change_rootdir_to_noshard.sh instance /newrootdir/dir</td></tr><tr><td>change_rootdir_to_shard.sh</td><td>修改zookeeper根目录至shard模式</td><td>./change_rootdir_to_shard.sh instance /newrootdir/dir</td></tr><tr><td>dcagent_tokafka</td><td>代理进程，用于和kafka交互</td><td>　</td></tr><tr><td>load_data</td><td>数据加载</td><td>./load_data mode0/mode1 proxy_host proxy_port user password db_table shardkey_index/auto  file terminate enclosed [split_size]</td></tr><tr><td>md5</td><td>文件校验</td><td>./md5</td></tr><tr><td>mysql-proxy</td><td>mysql代理，用于实现读写分离、负载均衡</td><td>./mysql-proxy /data/tdsql_run/15065/gateway/conf/instance_15065.cnf</td></tr><tr><td>mysql-proxyd</td><td>用于启停proxy实例</td><td>./mysql-proxyd instance {start|stop|restart|status}</td></tr><tr><td>mysql-proxy_old</td><td>mysql-proxy的旧版本</td><td>./mysql-proxyd_old instance {start|stop|restart|status}</td></tr><tr><td>replacetemplate</td><td>模板替换</td><td>./replacetemplate templatefile outputfile req</td></tr><tr><td>restartbinlogproduct.sh</td><td>重启binlogproduct.sh</td><td>./restartbinlogproduct.sh</td></tr><tr><td>restart_cgroup.sh</td><td>重启指定的proxy instance</td><td>./restart_cgroup.sh instance_15065</td></tr><tr><td>restartdcagent_tokafka_cgroup.sh</td><td>cgroup下重启agent_tokafka</td><td>./restartdcagent_tokafka_cgroup.sh</td></tr><tr><td>restartdcagent_tokafka.sh</td><td>重启agent_tokafka</td><td>./restartdcagent_tokafka.sh</td></tr><tr><td>restart_proxy.sh</td><td>重启proxy instance</td><td>./restart_proxy.sh instance_test</td></tr><tr><td>restart_router_cgroup.sh</td><td>cgroup下重启proxy instance</td><td>./restart.sh instance_test</td></tr><tr><td>restart.sh</td><td>重启proxy instance</td><td>./restart.sh instance_test</td></tr><tr><td>router_update</td><td>router更新</td><td>./router_update /data/tdsql_run/15065/gateway/conf/instance_15065.cnf</td></tr><tr><td>safeshell</td><td>用于Ruby开发的安全shell环境(SafeShell lets you execute shell commands and get the resulting output, but without the security problems of Ruby&#39;s backtick operator.)</td><td>非执行文件</td></tr><tr><td>srm</td><td>tdsql慢删除工具</td><td>./srm [filename]</td></tr><tr><td>srmnew</td><td>tdsql慢删除工具</td><td>./srmnew [-c countPerSec(default is 4)]  filelist</td></tr><tr><td>start_cgroup.sh</td><td>cgroup下启动指定的proxy instance</td><td>./start_cgroup.sh instance_15065</td></tr><tr><td>startdcagent_tokafka_cgroup.sh</td><td>cgroup下启动agent_tokafka</td><td>./startdcagent_tokafka_cgroup.sh</td></tr><tr><td>startdcagent_tokafka.sh</td><td>启动agent_tokafka进程</td><td>./startdcagent_tokafka.sh</td></tr><tr><td>start_proxy.sh</td><td>使用mysql-proxyd启动指定instance</td><td>./start_proxy.sh instance_test</td></tr><tr><td>start_router_cgroup.sh</td><td>cgroup下启动指定的proxy instance</td><td>./start_router_cgroup.sh instance_test</td></tr><tr><td>start_router.sh</td><td>启动指定proxy instance</td><td>./start_router.sh instance_test</td></tr><tr><td>start.sh</td><td>启动指定的mysql-proxy instance</td><td>./start.sh instance_test</td></tr><tr><td>stopdcagent_tokafka.sh</td><td>停止agent_tokafka</td><td>./stopdcagent_tokafka.sh  conf</td></tr><tr><td>stop_proxy.sh</td><td>停止指定的proxy instance</td><td>./stop_proxy.sh  instance_15065</td></tr><tr><td>stop_router.sh</td><td>停止指定的router</td><td>./stop_router.sh instance_15065</td></tr><tr><td>stop.sh</td><td>停止指定的proxy instance</td><td>./stop.sh instance_15065</td></tr><tr><td>stop_version.sh</td><td>停止指定版本的proxy</td><td>./stop_version.sh instance_3337 pid</td></tr><tr><td>switchdcagent_tokafka.sh</td><td>agent_tokafka模式切换</td><td>./switchdcagent_tokafka.sh conf [openDC/closeDC]</td></tr><tr><td>tdsql_addto_cgroup</td><td>用于将instance加入到cgroup</td><td>./tdsql_addto_cgroup  --port mysql_instance_port \ --pid xxx --cgrouptype cpu,blkio</td></tr><tr><td>tdsql_cgroup_build</td><td>用于cgroup对instance配置编排</td><td>./tdsql_cgroup_build --instanceport instanceport --cpu_percent 20 --mode add|modify|init</td></tr><tr><td>update_version.sh</td><td>版本更新</td><td>./update_version.sh instance_15065</td></tr><tr><td>zk_tool</td><td>zookeeper管理工具</td><td>./zk_tool del_node/del_node_force zkiplist path</td></tr></tbody>
</table></figure>

## Zookeeper
<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/application/zookeeper/bin/</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>zkCleanup.sh</td><td>清理旧的事务日志和快照</td><td>./zkCleanup.sh 参数1 -n 参数2。 其中： 参数1，zk data目录，即zoo.cfg文件中dataDir值 参数2，保存最近的多少个快照</td></tr><tr><td>zkCli.cmd</td><td>zk的简易客户端工具，可以对zookeeper服务端数据进行各种操(Windows平台)</td><td>./zkCli.cmd -server IP:port</td></tr><tr><td>zkCli.sh</td><td>zk的简易客户端工具，可以对zookeeper服务端数据进行各种操(Linux平台)</td><td>./zkCli.sh -server IP:port</td></tr><tr><td>zkEnv.cmd</td><td>设置zk环境变量（Windows平台）</td><td>设置zookeeper启动时的环境变量，这个脚本不要单独执行,它需要嵌入到zkServer.cmd或者其他脚本中使用</td></tr><tr><td>zkEnv.sh</td><td>设置zk环境变量（Linux平台）</td><td>设置zookeeper启动时的环境变量，这个脚本不要单独执行,它需要嵌入到zkServer.sh或者其他脚本中使用</td></tr><tr><td>zkServer.cmd</td><td>zookeeper服务器的启动停止重启和状态查询(Windows平台)</td><td>./zkServer.cmd {start|start-foreground|stop|restart|status|upgrade|print-cmd}</td></tr><tr><td>zkServer.sh</td><td>zookeeper服务器的启动停止重启和状态查询(Linux平台)</td><td>./zkServer.sh {start|start-foreground|stop|restart|status|upgrade|print-cmd}</td></tr><tr><td>zkTxnLogToolkit.cmd</td><td>ZooKeeper附带的命令行工具，能够恢复带有损坏CRC的事务日志条目(Windows平台)</td><td>./zkTxnLogToolkit.cmd log.100000001</td></tr><tr><td>zkTxnLogToolkit.sh</td><td>ZooKeeper附带的命令行工具，能够恢复带有损坏CRC的事务日志条目(Linux平台)</td><td>./zkTxnLogToolkit.sh log.100000001</td></tr></tbody>
</table></figure>

## scheduler/manager

<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/application/scheduler/bin</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>agent_config</td><td>agent全局配置修改</td><td>./agent_config --mode modify|remove --option ocagent_port --value 8966</td></tr><tr><td>alter_slave_threads</td><td>修改MariaDB并行复制线程数量（废弃，勿用）</td><td>弃用</td></tr><tr><td>backupZkInfo</td><td>备份ZK元数据信息</td><td>./backupZkInfo </td></tr><tr><td>base64_decrypt</td><td>base64解密</td><td>./base64_decrypt [passwd] [key]</td></tr><tr><td>base64_encrypt</td><td>base64加密</td><td>./base64_encrypt [plaintext] [key]</td></tr><tr><td>change_proxygroup</td><td>老版本修改网关组reserved_count（目前已废弃）</td><td>弃用</td></tr><tr><td>change_proxyport</td><td>老版本升级网关组用（已废弃）</td><td>弃用</td></tr><tr><td>check_and_create_pidmap</td><td>检查主资源DB的pidmap节点，节点不存在则创建</td><td>./check_and_create_pidmap [ip]</td></tr><tr><td>check_port</td><td>检查资源节点端口状态是否正确</td><td>./check_port all</td></tr><tr><td>check_sets_is_specid</td><td>检查实例是否为按照specid比例购买</td><td>./check_sets_is_specid [set id ]</td></tr><tr><td>close_percona_encrypt</td><td>关闭percona加密</td><td>./close_percona_encrypt setname/groupid</td></tr><tr><td>collection_mariadb_zk_mistake</td><td>mariadb/zk做错误信息采集</td><td>./collection_mariadb_zk_mistake</td></tr><tr><td>create_db_stat</td><td>创建db状态信息</td><td>./create_db_stat config_path config_path setname</td></tr><tr><td>create_lvs_mode</td><td>创建lvs模式(可以指定Tunneling或者Non-arp device模式)</td><td>./create_lvs_mode [MODE] (TUN/DR)</td></tr><tr><td>create_stopdir</td><td>创建stopdir</td><td>./create_stopdir</td></tr><tr><td>dbinsert</td><td>数据插入</td><td>./dbinsert ip port user passwd rule</td></tr><tr><td>delete_unfinish_jobs</td><td>删除未完成任务（已废弃）</td><td>弃用</td></tr><tr><td>del_set</td><td>删除指定set</td><td>./del_set subrootdir setname</td></tr><tr><td>fix_appid</td><td>功能未知，无法使用，已废弃</td><td>弃用</td></tr><tr><td>fix_logdisk_by_setname</td><td>修正实例的logdisk资源</td><td>./fix_logdisk_by_setname  groupid/noshard  setname</td></tr><tr><td>fix_machine</td><td>功能未知，无法使用，已废弃</td><td>弃用</td></tr><tr><td>fix_pidmap</td><td>修复pidmap节点（已废弃）</td><td>弃用</td></tr><tr><td>fix_setrun_mem</td><td>修正DB的内存资源</td><td>./fix_setrun_mem master_ip</td></tr><tr><td>get_hb</td><td>用于取得节点心跳信息</td><td>./get_hb subrootdir all|host</td></tr><tr><td>get_set_info</td><td>获取指定set相关信息</td><td>./get_set_info subrootdir [setname]</td></tr><tr><td>get_sets</td><td>获取所有set相关信息</td><td>./get_sets</td></tr><tr><td>lvs_tool</td><td>lvs管理工具</td><td>./lvs_tool queryLvsMode all</td></tr><tr><td>manager</td><td>启动manager</td><td>./manager</td></tr><tr><td>manager_mig</td><td>与manager程序完全相同，仅名字区别</td><td>./manager</td></tr><tr><td>manaul_switch</td><td>主从切换</td><td>/manaul_switch user subrootdir setname master [special_slave]</td></tr><tr><td>manual_set</td><td>实例管理，设置实例免切等</td><td>./manual_set add_mnoswitch noshard all 1 24 ./manual_set list_mnoswitch noshard all</td></tr><tr><td>modify_election</td><td>选举节点设置</td><td>./modify_election subrootdir set host_ip_port is_election</td></tr><tr><td>modify_manager_variable</td><td>manager变量设置</td><td>./modify_manager_variable --offlinehost_timeout 10</td></tr><tr><td>modify_specinfo_auto</td><td>节点规格信息更改(CPU/MEMORY/DATA_DISK/LOG_DISK)</td><td>./modify_specinfo_auto --machine Machine type</td></tr><tr><td>monitor_sche</td><td>监控scheduler程序</td><td>./monitor_sche</td></tr><tr><td>newslicejob</td><td>用于手动发起垂直扩容任务（建议使用OSS发起任务）</td><td>./newslicejob subrootdir myuser mypassword srcset dstset begin_time end_time</td></tr><tr><td>noshard_create_set</td><td>创建非分布式set</td><td>./noshard_create_set subrootdir user setname masterip_port</td></tr><tr><td>noshard_privs</td><td>非分布式set权限管理_旧版本</td><td>./noshard_privs setname grant user password password_mode 1 db * table * privileges SELECT, INSERT, UPDATE, DELETE</td></tr><tr><td>noshard_privs-new</td><td>非分布式set权限管理_新版本</td><td>./noshard_privs-new setname grant user password password_mode 1 db * table * privileges SELECT, INSERT, UPDATE, DELETE</td></tr><tr><td>oc_tool</td><td>参考oc agent，同一工具</td><td>　</td></tr><tr><td>proxy_machine_remove</td><td>proxy机器删除</td><td>./proxy_machine_remove --ip</td></tr><tr><td>proxy_machine_report</td><td>proxy机器信息上报</td><td>./proxy_machine_report --ip</td></tr><tr><td>proxy_tool</td><td>proxy_tool管理工具，例如可以停止指定task</td><td>./proxy_tool  toptask  type  groupid(noshard) setid(jobid)</td></tr><tr><td>recoverZkInfo</td><td>将备份的zookeeper数据恢复到zookeeper</td><td>　</td></tr><tr><td>replacehost</td><td>节点替换</td><td>./replacehost subrootdir setname jobtype[add, replace, delete]  dsthost  srchost[only replace host need]</td></tr><tr><td>resource_fport</td><td>功能未知，源码丢失，废弃</td><td>弃用</td></tr><tr><td>resource_fport_mig</td><td>功能未知，源码丢失，废弃</td><td>弃用</td></tr><tr><td>resource_report</td><td>资源信息上报</td><td>./resource_report --ip &quot;host ip&quot;</td></tr><tr><td>resource_tool</td><td>tdsql集群资源管理，可以添加删除实例</td><td>./resource_tool addInstance pattern machine dbversion fenceid specid</td></tr><tr><td>safeshell</td><td>用于Ruby开发的安全shell环境(SafeShell lets you execute shell commands and get the resulting output, but without the security problems of Ruby&#39;s backtick operator.)</td><td>非执行文件</td></tr><tr><td>scan_db_port</td><td>扫描db端口</td><td>./scan_db_port</td></tr><tr><td>scheduler</td><td>启动scheduler</td><td>./scheduler /data/application/scheduler/bin</td></tr><tr><td>sshpass</td><td>用于非交互的ssh 密码验证，使用-p参数指定明文密码，然后直接登录远程服务器</td><td>sshpass -p xxx ssh root@ip</td></tr><tr><td>sshpass_pack.sh</td><td>远程服务器管理工具</td><td>./sshpass_pack.sh [password] [user] [ip] [port] <command> &lt;oc_tool path&gt;</td></tr><tr><td>sshpass_pack.sh_old</td><td>用于Keeper调用oc_tool工具发送指令的脚本（已废弃）</td><td>./sshpass_pack.sh_old [password] [user] [ip] [port] <command> &lt;oc_tool path&gt;</td></tr><tr><td>start_manager.sh</td><td>启动scheduler/manager</td><td>./start_manager.sh</td></tr><tr><td>stop_manager.sh</td><td>停止scheduler/manager</td><td>./stop_manager.sh</td></tr><tr><td>update</td><td>升级MIG版本，例如从MIG7.1升级到MIG8.0</td><td>./update version</td></tr><tr><td>zk_operate</td><td>zk配置工具</td><td>./zk_operate get  path &#39;content&#39;</td></tr><tr><td>zk_recursion_print</td><td>递归打印根目录树</td><td>./zk_recursion_print zklist rootdir</td></tr><tr><td>zk_recursion_setacl</td><td>递归设置目录ACL权限</td><td>./zk_recursion_setacl zklist rootdir 0/1    0 mean set acl by word:anyone    1 mean set acl by tdsql user</td></tr><tr><td>zk_sets</td><td>用于实例数据拷贝（源码丢失，废弃）</td><td>弃用</td></tr><tr><td>zone_init</td><td>zone初始化，需要先停止scheduler</td><td>./zone_init</td></tr><tr><td>zone_privs</td><td>groupshard 版本授权工具，非 ip 透传模式</td><td>./zone_privs zone myuser mypassword dropdatabase db</td></tr><tr><td>zone_privs-new</td><td>groupshard 版本授权工具，ip 透传模式</td><td>./zone_privs-new zone myuser mypassword dropdatabase db</td></tr></tbody>
</table></figure>

## OSS
<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/application/oss/bin/</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>oss_server</td><td>提供http操作TDSQL的接口</td><td>/data/application/oss/boot/start.sh /data/application/oss/boot/stop.sh</td></tr></tbody>
</table></figure>

## Monitor
<figure><table>
<thead>
<tr><th colspan=3>collector组件:</th></tr></thead>
<tbody><tr><td colspan=3>文件所在路径:/data/application/tdsql_collector/bin</td></tr><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>encrypt_tool</td><td>加密工具</td><td>./encrypt_tool 0 12345</td></tr><tr><td>monitor.sh</td><td>collector进程监控脚本</td><td>由crontab定期执行</td></tr><tr><td>restart.sh</td><td>重启CollectorApplication</td><td>./restart.sh</td></tr><tr><td>start.sh</td><td>启动CollectorApplication</td><td>./start.sh</td></tr><tr><td>stop.sh</td><td>停止CollectorApplication</td><td>./stop.sh</td></tr><tr><td>tnm2_link.sh</td><td>创建指定文件的软链接</td><td>　</td></tr><tr><td>upgrade.sh</td><td>升级CollectorApplication脚本</td><td>./upgrade.sh</td></tr><tr><td>up.sh</td><td>升级工具</td><td>弃用</td></tr><tr><td colspan=3>analyze组件:</td></tr><tr><td colspan=3>文件所在路径:/data/application/tdsql_analysis/bin</td></tr><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>alarm_test.sh</td><td>告警脚本</td><td>./alarm_test.sh  dir  msg reciever  mLevel  clusterIds  alarmIds</td></tr><tr><td>confsync.sh</td><td>启动脚本</td><td>java参数初始化，不单独使用</td></tr><tr><td>encrypt_tool</td><td>加密工具</td><td>./encrypt_tool 0 12345</td></tr><tr><td>monitor.sh</td><td>analysis进程监控脚本</td><td>由crontab调度</td></tr><tr><td>restart.sh</td><td>重启analysisApplication</td><td>./restart.sh</td></tr><tr><td>start.sh</td><td>启动analysisApplication</td><td>./start.sh</td></tr><tr><td>stop.sh</td><td>停止analysisApplication</td><td>./stop.sh</td></tr><tr><td>upgrade.sh</td><td>升级analysisApplication脚本</td><td>./upgrade.sh</td></tr></tbody>
</table></figure>

## Clouddba
<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/application/clouddba/bin/</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>analyze_monitorlog.py</td><td>监控日志分析</td><td>python analyze_monitorlog.py</td></tr><tr><td>clouddba-client.py</td><td>clouddba客户端工具</td><td>./clouddba-client.py [-h] [-c CONFIG] [-H HOST] [-p PORT] -q REQUEST</td></tr><tr><td>clouddba-client.py.bak</td><td>clouddba-client.py的旧版本</td><td>./clouddba-client.py.bak [-h] [-c CONFIG] [-H HOST] [-p PORT] -q REQUEST</td></tr><tr><td>dt2ts.sh</td><td>date类型转换为timestamp类型</td><td>./dt2ts.sh &quot;2021-03-30 19:12:36&quot; </td></tr><tr><td>git-version</td><td>代码版本信息</td><td>非执行文件</td></tr><tr><td>master-switch-analysis.py</td><td>节点切换原因探测</td><td>./master-switch-analysis.py [-h] [-d DUMP_LOG_DIR] [-st SWITCH_TIME]                  [-o OUTPUT] [-dn DUMP_LOG_DIR_NAME]                  [--since_time SINCE_TIME]                  [--until_time UNTIL_TIME] [--getdir]</td></tr><tr><td>oc_tool</td><td>oc配置管理工具</td><td>./oc_tool [-fdkcvn] [-o option] [-P port] [-l ratelimit] [-t timeout] [-p password] [user@]hostname [command]</td></tr><tr><td>parse-processlist-log.sh</td><td>分析指定时间段的慢查询</td><td>./parse-processlist-log.sh since_time(int) until_time(int)</td></tr><tr><td>password_encrypt</td><td>对指定密码加密</td><td>./password_encrypt  your_password</td></tr><tr><td>proxy_log_analyzer</td><td>可用于分析proxy的常规日志和事务型日志</td><td>./proxy_log_analyzer -t 1</td></tr><tr><td>restart.sh</td><td>重启扁鹊模块</td><td>./restart.sh</td></tr><tr><td>safeshell</td><td>用于Ruby开发的安全shell环境(SafeShell lets you execute shell commands and get the resulting output, but without the security problems of Ruby&#39;s backtick operator.)</td><td>./safeshell &#39;[cmd]&#39;</td></tr><tr><td>sql-optimizer</td><td>sql优化模块，可以给出指定SQL的优化建议</td><td>./sql-optimizer -utdsqlpcloud -h172.27.32.110 -P15065 -p&#39;tdsqlpcloud&#39; -Dtdsqlpcloud -q &#39;select * from  t_db_parameter_config_items&#39;</td></tr><tr><td>srm</td><td>tdsql慢删除工具</td><td>./srm [filename]</td></tr><tr><td>start.sh</td><td>启动扁鹊模块</td><td>./start.sh</td></tr><tr><td>stop.sh</td><td>停止扁鹊模块</td><td>./stop.sh</td></tr><tr><td>tags</td><td>用于代码管理</td><td>非执行文件</td></tr><tr><td>tdsql-diagnosis</td><td>用于tdsql问题诊断</td><td>./tdsql-diagnosis options: Options:  -h [ --help ]      show usage message  -v [ --version ]    show version info  -c [ --config ] arg   config file path  -d [ --daemon ]     run as daemon</td></tr><tr><td>tdsql_inspection.py</td><td>tdsql巡检脚本</td><td>基础巡检： ./tdsql_inspection.py  -b </td></tr><tr><td>ts2dt.sh</td><td>timestamp类型转换为date类型</td><td>　</td></tr><tr><td>update-config.py</td><td>配置更新脚本</td><td>./update-config.py  diagnosis_conf_file</td></tr></tbody>
</table></figure>

## Kafka
<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/application/kafka/bin/</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>connect-distributed.sh</td><td>用于启动多节点的Distributed模式的Kafka Connect组件</td><td>./connect-distributed.sh config/connect-distributed.properties</td></tr><tr><td>connect-standalone.sh</td><td>用于启动单节点的Standalone模式的Kafka Connect组件</td><td>./connect-standalone.sh config/connect-standalone.properties connector1.properties [connector2.properties ...]</td></tr><tr><td>kafka-acls.sh</td><td>Kafka ACL权限管理客户端工具</td><td>设置哪些用户可以访问Kafka的哪些TOPIC权限： ./kafka-acls.sh \   --authorizer-properties  zookeeper.connect=zookeeper:port \   --add \   --cluster \   --operation alter \   --deny-principal User:ANONYMOUS</td></tr><tr><td>kafka-broker-api-versions.sh</td><td>用于验证不同Kafka版本之间服务器和客户端的适配性(需要指定Kafka Broker)</td><td>./kafka-broker-api-versions.sh \   --bootstrap-server kafka-host:port</td></tr><tr><td>kafka-configs.sh</td><td>Kafka动态配置管理脚本</td><td>./kafka-configs.sh \   --zookeeper zookeeper_host:port \   --entity-type topics \   --entity-name topic_name \   --alter \   --add-config max.message.bytes=10485760</td></tr><tr><td>kafka-console-consumer.sh</td><td>kafka消费者控制</td><td>./kafka-console-consumer.sh \  --bootstrap-server  kafka-host:port \  --topic test \  --from-beginning</td></tr><tr><td>kafka-console-producer.sh</td><td>kafka生产者控制</td><td>./kafka-console-producer.sh \   --bootstrap-server  kafka-host:port  \   --topic test</td></tr><tr><td>kafka-consumer-groups.sh</td><td>kafka消费者组相关配置</td><td>重设消费者组位移： ./kafka-consumer-groups.sh \   --bootstrap-server  kafka-host:port \   --group test-group \   --reset-offsets \   --all-topics \    --to-latest \   --execute</td></tr><tr><td>kafka-consumer-perf-test.sh</td><td>kafka消费者性能测试脚本</td><td>./kafka-consumer-perf-test.sh \   --broker-list kafka-host:port \   --messages 10000000 \   --topic test</td></tr><tr><td>kafka-delegation-tokens.sh</td><td>使用Token认证机制时对Token的操作</td><td>为用户生成token: ./kafka-delegation-tokens.sh \  --create \  --bootstrap-server &lt;ip1:port, ip2:port,...&gt; \  --max-life-time-period &lt;Long: max life period in milliseconds&gt; \  --command-config <config file> \  --renewer-principal User:<user name></td></tr><tr><td>kafka-delete-records.sh</td><td>用于删除Kafka的分区消息，由于Kafka有自己的自动消息删除策略，使用频率不高</td><td>删除制定的partition和offset： ./kafka-delete-records.sh \  --bootstrap-server localhost:port \  --offset-json-file ./offset.json  offset.json的内容： {&quot;partitions&quot;: [{&quot;topic&quot;: &quot;mytest&quot;, &quot;partition&quot;: 0, &quot;offset&quot;: 90}], &quot;version&quot;:1 }</td></tr><tr><td>kafka-dump-log.sh</td><td>查看Kafka消息文件的内容，包括消息的各种元数据信息、消息体数据</td><td>./kafka-dump-log.sh \  --files  /var/local/kafka/data/test-topic-0/0000000100.log</td></tr><tr><td>kafka-log-dirs.sh</td><td>查询各个Broker上的各个日志路径的磁盘占用情况</td><td>./kafka-log-dirs.sh  \  --bootstrap-server broker:port \  --describe \  --broker-list broker.id_list \  --topic-list topics</td></tr><tr><td>kafka-mirror-maker.sh</td><td>用于在Kafka集群间实现数据镜像</td><td>./kafka-mirror-maker.sh  --consumer.config consumer.properties  --producer.config producer.properties --whitelist &quot;my-topic1,my-topic2&quot;  以上consumer.properties配置文件: bootstrap.servers=broker_ip:port group.id=mirror_maker-group enable.auto.commit=true auto.offset.reset=earliest auto.commit.interval.ms=1000  以上producer.properties配置文件： bootstrap.servers=broker_ip:port acks=1 linger.ms=100 batch.size=16384 retries=3</td></tr><tr><td>kafka-preferred-replica-election.sh</td><td>触发preferred replica选举</td><td>对所有topic进行preferred replica election： ./kafka-preferred-replica-election --zookeeper cdh-002/kafka</td></tr><tr><td>kafka-producer-perf-test.sh</td><td>生产者性能测试脚本</td><td>设置不同消息数进行压测： ./kafka-producer-perf-test.sh --topic test_perf --num-records 100000 --record-size 2000  --throughput 3000 --producer-props bootstrap.servers=IP:PORT   ./kafka-producer-perf-test.sh --topic test_perf --num-records 1000000 --record-size C4000  --throughput 6000 --producer-props bootstrap.servers=IP:PORT   ./kafka-producer-perf-test.sh --topic test_perf --num-records 10000000 --record-size 6000  --throughput 8000 --producer-props bootstrap.servers=IP:PORT</td></tr><tr><td>kafka-reassign-partitions.sh</td><td>用于执行分区副本迁移以及副本文件路径迁移</td><td>./kafka-reassign-partitions.sh --zookeeper hostname:port --topics-to-move-json-file topic.json  --broker-list  &quot;0,1,2,4&quot;  --generate  以上topic.json文件： {   &quot;topics&quot;: [     {&quot;topic&quot;: &quot;test&quot;}   ],   &quot;version&quot;: 1 }</td></tr><tr><td>kafka-replica-verification.sh</td><td>复制进度验证脚本</td><td>./kafka-replica-verification.sh \ --broker-list IP1:PORT,IP2:PORT,IP3,PORT  -topic-white-list test</td></tr><tr><td>kafka-run-class.sh</td><td>用于查看消费了多少条数据</td><td>./kafka-run-class.sh kafka.tools.ConsumerOffsetChecker \ --zookeeper IP1:PORT,IP2:PORT,IP3:PORT \ --group G1 --topic test</td></tr><tr><td>kafka-server-start.sh</td><td>启动Kafka Broker进程</td><td>./kafka-server-start.sh -daemon config/server.properties</td></tr><tr><td>kafka-server-stop.sh</td><td>停止Kafka Broker进程</td><td>./kafka-server-stop.sh</td></tr><tr><td>kafka-streams-application-reset.sh</td><td>用于给Kafka Streams应用程序重设位移，以便重新消费数据</td><td>./kafka-streams-application-reset.sh \ --application-id <id> \ --bootstrap-servers host1,port1,host2,port2,host3,port3 \ --intermediate-topics <list> \ --input-topics <list>  \ --zookeeper host1:port1,host2:port2,host3,port3</td></tr><tr><td>kafka-topics.sh</td><td>用于管理所有topic，比如创建一个topic</td><td>./kafka-topics.sh \ --bootstrap-server broker_host:port \ --create \ --topic my_topic_name \ --partitions 1 --replication-factor 1</td></tr><tr><td>kafka-verifiable-consumer.sh</td><td>测试验证消费者功能</td><td>./kafka-verifiable-consumer.sh \ --broker-list IP:PORT \ --topic first \ --group-id group.demo \ --max-messages 2</td></tr><tr><td>kafka-verifiable-producer.sh</td><td>测试验证生产者功能</td><td>./kafka-verifiable-producer.sh \ --broker-list IP:PORT \ --topic first \ --message-create-time 1527351382000 \ --value-prefix 1 \ --repeating-keys 10 \ --max-messages 20</td></tr><tr><td>trogdor.sh</td><td>Kafka的测试框架，用于执行各种基准测试和负载测试</td><td>./trogdor.sh [action] [options]</td></tr><tr><td>zookeeper-security-migration.sh</td><td>更新kafka数据中的zookeeper的 ACL</td><td>./zookeeper-security-migration \ --zookeeper.acl=secure \ --zookeeper.connect={host}:{port}/{path}</td></tr><tr><td>zookeeper-server-start.sh</td><td>启动zookeeper，Kafka启动前需要先启动zookeeper</td><td>./zookeeper-server-start.sh -daemon config/zookeeper.properties </td></tr><tr><td>zookeeper-server-stop.sh</td><td>停止zookeeper，先停止Kafka，再停止zookeeper</td><td>./zookeeper-server-stop.sh</td></tr><tr><td>zookeeper-shell.sh</td><td>查看kafka在zookeeper中的配置</td><td>./zookeeper-shell.sh zookeeper_host:port[/path] [args…]</td></tr></tbody>
</table></figure>

## Consumer
<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/application/consumer/bin/</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>binlogconsumer</td><td>binlog日志消费和重放模块</td><td>./binlogconsumermgn --zklist 172.27.32.13:2118,172.27.32.6:2118,172.27.32.10:2118 --zkrootpath /tdsqlzk --kafkazklist 172.27.32.13:2118,172.27.32.6:2118,172.27.32.10:2118 --kafkazkrootpath /kafka --dev eth0</td></tr><tr><td>binlogconsumermgn</td><td>binlogconsumer的管理模块</td><td>启动： ./binlogconsumermgn --zklist IP:PORT --zkrootpath /noshard1 \  --kafkazklist  IP:PORT --kafkazkrootpath /kafka --dev eth0 停止： ps -ef |grep binlogconsumermgn | grep -v &#39;grep&#39;| awk &#39;{print $2}&#39; | xargs kill -9</td></tr><tr><td>binlogproducter</td><td>解析所在节点的 binlog并push到消息队列</td><td>./binlogproducter ../conf/mysqlagent_4001.xml</td></tr><tr><td>binlogproducter_percona</td><td>binlogproducter的percona版本</td><td>./binlogproducter_percona ../conf/mysqlagent_4001.xml</td></tr><tr><td>createZkFlag</td><td>　</td><td>　</td></tr><tr><td>incrementalcheck</td><td>日志消费增量检查</td><td>./incrementalcheck --orgzkiplist IP:PORT \ --checklogpath ../data/jobid/checklog</td></tr><tr><td>install_dep.sh</td><td>安装oracle相关文件</td><td>./install_dep.sh</td></tr><tr><td>kafkamsgtool</td><td>Kafka管理工具，可用于设置batchsize等参数</td><td>./kafkamsgtool --zklist IP:PORT --zkrootpath /noshard1 \ --kafkazklist  IP:PORT --kafkazkrootpath /kafka --batchsize 1</td></tr><tr><td>kafkaUpdate</td><td>　</td><td>./kafkaUpdate zkip ziroot file_of_setname productor_switch</td></tr><tr><td>listUniqueId</td><td>　</td><td>./listUniqueId zkip zkroot setnames</td></tr><tr><td>multisrcsync_log_bak_clean.py</td><td>对于binlogconsumer产生的日志进行间歇性备份和清理</td><td>由crontab调用</td></tr><tr><td>mydumper_tdsql</td><td>tdsql for mysql多线程数据dump工具</td><td>./mydumper_tdsql  --lock-all-tables=FALSE  --host=127.0.0.1 --port=3306 --user=app --password=123456  --trx-consistency-only=true  --databases &quot;test&quot; &gt; /data/mysqldump/test.sql</td></tr><tr><td>myloader_tdsql</td><td>tdsql for mysql多线程数据加载工具</td><td>./myloader_tdsql -u root -p 123456 -B test -d /data/mysqldump/</td></tr><tr><td>mysql</td><td>mysql客户端工具</td><td>mysql -u root -p 123456</td></tr><tr><td>mysqldump</td><td>mysql单线程dump工具</td><td>./mydump  --lock-tables=FALSE --protocol=tcp --set-gtid-purged=OFF  --host=127.0.0.1 --port=3306 --user=app --password=123456  --single-transaction=TRUE --master-data=2 --databases &quot;test&quot; &gt; /data/mysqldump/test.sql</td></tr><tr><td>newjoboncesync</td><td>　</td><td>./newjoboncesync --zkiplist IP:PORT --zkrootpath /noshard1 \ --mode execute --truncate 1</td></tr><tr><td>oncesynctable</td><td>　</td><td>　</td></tr><tr><td>oracel.dep.tgz</td><td>oracle部分组件安装包</td><td>由install_dep.sh执行安装</td></tr><tr><td>runtime.err</td><td>记录运行出错的日志</td><td>tail -f runtime.err</td></tr><tr><td>safeshell</td><td>用于Ruby开发的安全shell环境</td><td>非执行文件</td></tr><tr><td>sqlldr</td><td>oracle数据加载工具</td><td>sqlldr userid=scott/tiger@emp control=/data/data.ctl log=/data/log20210330.log  bad=/data//bad20210330.bad  /data/data.ctl文件内容： options(SKIP=1,ROWS=1000,ERRORS=0) load data CHARACTERSET  utf8 infile &#39;/data/emp.csv&#39; APPEND into table scott.emp fields terminated by &#39;,&#39; trailing nullcols ( a,  b, c, d )</td></tr><tr><td>sqlplus</td><td>oracle客户端访问工具</td><td>sqlplus username/password@service_name</td></tr></tbody>
</table></figure>

## OnlineDDL
<figure><table>
<thead>
<tr><th colspan=3>文件所在路径:/data/application/onlineddl/bin/</th></tr></thead>
<tbody><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>ddlperformer</td><td>online-ddl执行进程</td><td>由ddlperformermng调度</td></tr><tr><td>ddlperformermng</td><td>online-ddl管理进程</td><td>由crontab调度</td></tr><tr><td>plugin.pl</td><td>pt_online_schema_change插件</td><td>无需单独使用</td></tr><tr><td>pt-online-schema-change</td><td>在线进行表结构变更</td><td>添加表字段new_student： pt-online-schema-change \ --alter=&quot;add new_student varchar(10) NOT NUll DEFAULT &#39;&#39; \ COMMENT &#39;新学生&#39; ;&quot;  \ --execute  \ --print \ --max-lag=5 D=test,t=users,u=root,p=123,S=/tmp/mysql.sock \ --no-check-replication-filters \ --max-load=&quot;Threads_running=100&quot; \ --critical-load=&quot;Threads_running=120&quot; \ --charset=utf8  \ --chunk-size=100</td></tr></tbody>
</table></figure>

## ELK
<figure><table>
<thead>
<tr><th colspan=3>es组件:</th></tr></thead>
<tbody><tr><td colspan=3>文件所在路径:/data/application/es-install/es/master/bin/</td></tr><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>elasticsearch</td><td>用作全文检索(Linux平台)</td><td>启动： ./elasticsearch</td></tr><tr><td>elasticsearch.bat</td><td>用作全文检索(Windows平台)</td><td>启动： 先点击elasticsearch-service-x64.exe 再点击elasticsearch.bat</td></tr><tr><td>elasticsearch.in.bat</td><td>bin/elasticsearch.bat启动模式下，用于内存参数优化(Windows平台)</td><td>建议ES_MIN_MEM和ES_MAX_MEM最好设置为相同值</td></tr><tr><td>elasticsearch.in.sh</td><td>bin/elasticsearch启动模式下，用于内存参数优化(Linux平台)</td><td>建议ES_MIN_MEM和ES_MAX_MEM最好设置为相同值</td></tr><tr><td>elasticsearch-keystore</td><td>用户安全配置以及创建内置用户账号(Linux平台)</td><td>./elasticsearch-keystore passwd ./elasticsearch-keystore add user.name</td></tr><tr><td>elasticsearch-keystore.bat</td><td>用户安全配置以及创建内置用户账号(Windows平台)</td><td>./elasticsearch-keystore.bat passwd ./elasticsearch-keystore.bat add user.name</td></tr><tr><td>elasticsearch-plugin</td><td>elasticsearch插件管理(Linux平台)</td><td>./elasticsearch-plugin install [plugin_name] ./elasticsearch-plugin list elasticsearch-plugin remove [pluginname]</td></tr><tr><td>elasticsearch-plugin.bat</td><td>elasticsearch插件管理(Windows平台)</td><td>./elasticsearch-plugin.bat install [plugin_name] ./elasticsearch-plugin.bat list elasticsearch-plugin.bat remove [pluginname]</td></tr><tr><td>elasticsearch-service.bat</td><td>该脚本用于将elasticsearch安装为Windows服务(Windows平台)</td><td>cmd 进入bin目录下执行: elasticsearch-service.bat install</td></tr><tr><td>elasticsearch-service-mgr.exe</td><td>elasticsearch安装为Windows服务之后，可以用该程序进行GUI管理(Windows平台)</td><td>双击程序运行</td></tr><tr><td>elasticsearch-service-x64.exe</td><td>用于启动elasticsearch(64位 Windows平台)</td><td>启动： 先点击elasticsearch-service-x64.exe 再点击elasticsearch.bat</td></tr><tr><td>elasticsearch-service-x86.exe</td><td>用于启动elasticsearch(32位 Windows平台)</td><td>启动： 先点击elasticsearch-service-x86.exe 再点击elasticsearch.bat</td></tr><tr><td>lasticsearch-systemd-pre-exec</td><td>lasticsearch-systemd-pre-exec linux服务注册文件</td><td>无需单独使用</td></tr><tr><td>elasticsearch-translog</td><td>以丢失事务日志中包含的数据为代价来恢复分片中的部分数据，需要在关闭es后使用，如果你在es运行中执行这个命令，则将永久的丢失事物日志中的所有文档(Linux平台)</td><td>./elasticsearch-translog truncate -d [损坏的事务日志目录]</td></tr><tr><td>elasticsearch-translog.bat</td><td>以丢失事务日志中包含的数据为代价来恢复分片中的部分数据，需要在关闭es后使用，如果你在es运行中执行这个命令，则将永久的丢失事物日志中的所有文档(Windows平台)</td><td>./elasticsearch-translog.bat truncate -d [损坏的事务日志目录]</td></tr><tr><td colspan=3>logstash组件:</td></tr><tr><td colspan=3>文件所在路径:/data/application/es-install/logstash/bin/</td></tr><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>cpdump</td><td>用于查看checkpoint.head文件内容</td><td>./cpdump checkpoint.head</td></tr><tr><td>ingest-convert.sh</td><td>将Elasticsearch Ingest脚本转换为Logstash配置文件的工具</td><td>./ingest-convert.sh --input INPUT_FILE_URI --output OUTPUT_FILE_URI [--append-stdio]</td></tr><tr><td>logstash</td><td>运行logstash，用于日志检索，全站搜索等(Linux平台)</td><td>./logstash -e &#39;input { stdin { } } output { stdout {} }&#39;</td></tr><tr><td>logstash.bat</td><td>运行logstash，用于日志检索，全站搜索等(Windows平台)</td><td>./logstash.bat -e &#39;input { stdin { } } output { stdout {} }&#39;</td></tr><tr><td>logstash.lib.sh</td><td>logstash启动过程会引入lib文件ogstash.lib.sh</td><td>可以在该文件中设置JAVA_HOME等环境变量</td></tr><tr><td>logstash-plugin</td><td>用于logstash插件安装(Linux平台)</td><td>./logstash-plugin install [plugin_name]</td></tr><tr><td>logstash-plugin.bat</td><td>用于logstash插件安装(Windows平台)</td><td>./logstash-plugin.cmd install [plugin_name]</td></tr><tr><td>ruby</td><td>filters/ruby插件，用于日志信息解析</td><td>配置示例： filter {   ruby {     init =&gt; &quot;@kname = [&#39;client&#39;,&#39;servername&#39;,&#39;url&#39;,&#39;status&#39;,&#39;time&#39;,&#39;size&#39;,&#39;upstream&#39;,&#39;upstreamstatus&#39;,&#39;upstreamtime&#39;,&#39;referer&#39;,&#39;xff&#39;,&#39;useragent&#39;]&quot;     code =&gt; &quot;event.append(Hash[@kname.zip(event[&#39;message&#39;].split(&#39;|&#39;))])&quot;   } }</td></tr><tr><td>setup.bat</td><td>用于logstash的安装(Linux平台)</td><td>安装最后阶段会被执行，无须手动执行</td></tr><tr><td>system-install</td><td>用于logstash的安装(Windows平台)</td><td>安装最后阶段会被执行，无须手动执行</td></tr><tr></tr><tr><td colspan=3>kibana组件:</td></tr><tr><td colspan=3>文件所在路径:/data/application/es-install/kibana-5.6.4-linux-x86_64/bin/</td></tr><tr><td>文件名</td><td>功能说明(常用使用场景)</td><td>使用方法</td></tr><tr><td>kibana</td><td>为 Elasticsearch设计的开源分析和可视化平台</td><td>启动： ./kibana</td></tr><tr><td>kibana-plugin</td><td>用于安装kibana插件</td><td>./kibana-plugin install filename</td></tr></tbody>
</table></figure>
